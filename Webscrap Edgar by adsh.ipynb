{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping EDGAR - specific filling (adsh)\n",
    "#### adsh Accession Number. The 20-character string formed from the 18-digit number assigned by the SEC to each EDGAR submission.\n",
    "#### can be compared to https://www.sec.gov/dera/data/financial-statement-data-sets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Extracting ahef links from page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(link):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Mobile Safari/537.36'}\n",
    "\n",
    "    req = requests.get(link,headers=hdr)\n",
    "    content = req.content\n",
    "  \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check specific filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.sec.gov/Archives/edgar/data/0000831001/000110465921050513/0001104659-21-050513-index.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Extract link for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = get_data(url)\n",
    "soup = bs(html, \"html.parser\")\n",
    "rows = soup.find_all(\"tr\")\n",
    "for row in rows:\n",
    "    row_td = row.find_all(\"td\")\n",
    "    for file in row_td:\n",
    "        main_links = file.find_all('a')\n",
    "        for data in main_links:\n",
    "            data_list.append(data['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ix?doc=/Archives/edgar/data/831001/000110465921050513/c-20210210x8k.htm',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210xex99d1charter.htm',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210xex99d2bylaws.htm',\n",
       " '/ix?doc=/Archives/edgar/data/831001/000110465921050513/c-20210210xex993voti.htm',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210xex99d2bylaws001.jpg',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210xex99d1charter001.jpg',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210xex99d1charter002.jpg',\n",
       " '/Archives/edgar/data/831001/000110465921050513/0001104659-21-050513.txt',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210.xsd',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210_def.xml',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210_lab.xml',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210_pre.xml',\n",
       " '/Archives/edgar/data/831001/000110465921050513/c-20210210x8k_htm.xml']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Separate links with different file extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_htm = []\n",
    "file_xml = []\n",
    "file_html = []\n",
    "file_gif = []\n",
    "file_txt = []\n",
    "file_jpg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.htm'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(data_list[1])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extensions in data_list:\n",
    "    case = os.path.splitext(extensions)[1]\n",
    "    if case == '.htm':\n",
    "        file_htm.append(extensions)\n",
    "    elif case == '.html':\n",
    "        file_html.append(extensions)\n",
    "    elif case == '.xml':\n",
    "        file_xml.append(extensions) \n",
    "    elif case == '.gif':\n",
    "        file_gif.append(extensions)\n",
    "    elif case ==  '.txt':\n",
    "        file_txt.append(extensions)\n",
    "    elif case ==  '.jpg':\n",
    "        file_jpg.append(extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Archives/edgar/data/831001/000110465921050513/c-20210210_lab.xml'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_xml[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Converting htm links to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.isdir('../txt_files_main')):\n",
    "    print(\"directory already exists\")\n",
    "else:\n",
    "    os.mkdir('../txt_files_main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/ix?doc=/Archives/edgar/data/831001/000110465921050513/c-20210210x8k.htm\n",
      "https://www.sec.gov/Archives/edgar/data/831001/000110465921050513/c-20210210xex99d1charter.htm\n",
      "https://www.sec.gov/Archives/edgar/data/831001/000110465921050513/c-20210210xex99d2bylaws.htm\n",
      "https://www.sec.gov/ix?doc=/Archives/edgar/data/831001/000110465921050513/c-20210210xex993voti.htm\n"
     ]
    }
   ],
   "source": [
    "for htmlfiles in file_htm:\n",
    "    html = get_data(\"https://www.sec.gov\" + htmlfiles)\n",
    "    print(\"https://www.sec.gov\" + htmlfiles) # for debugging to see which htm will be saved as text file \n",
    "    soup = bs(html, features = \"html.parser\")\n",
    "    for script in soup([\"script\",\"style\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text()\n",
    "        # break into lines\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "    chunks = (pharse.strip() for line in lines for pharse in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    f = open(\"../txt_files_main/test\"+str(txt_no)+\".txt\",\"w\",encoding=\"utf-8\")\n",
    "    f.write(text)\n",
    "    txt_no+=1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Converting xml links to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.isdir('../txt_files_main_xml')):\n",
    "    print(\"directory already exists\")\n",
    "else:\n",
    "    os.mkdir('../txt_files_main_xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_no = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for htmlfiles in file_xml:\n",
    "    html = get_data(\"https://www.sec.gov\" + htmlfiles)\n",
    "    #print(\"https://www.sec.gov\" + htmlfiles) # for debugging to see which htm will be saved as text file \n",
    "    soup = bs(html, features = \"html.parser\")\n",
    "    for script in soup([\"script\",\"style\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text()\n",
    "        # break into lines\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "    chunks = (pharse.strip() for line in lines for pharse in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    f = open(\"../txt_files_main_xml/test\"+str(txt_no)+\".txt\",\"w\",encoding=\"utf-8\")\n",
    "    f.write(text)\n",
    "    txt_no+=1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Saving text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.isdir('../txt_files_main_txt')):\n",
    "    print(\"directory already exists\")\n",
    "else:\n",
    "    os.mkdir('../txt_files_main_txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_no = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for htmlfiles in file_txt:\n",
    "    html = get_data(\"https://www.sec.gov\" + htmlfiles)\n",
    "    #print(\"https://www.sec.gov\" + htmlfiles) # for debugging to see which htm will be saved as text file \n",
    "    soup = bs(html, features = \"html.parser\")\n",
    "    for script in soup([\"script\",\"style\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text()\n",
    "        # break into lines\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "    chunks = (pharse.strip() for line in lines for pharse in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    f = open(\"../txt_files_main_txt/test\"+str(txt_no)+\".txt\",\"w\",encoding=\"utf-8\")\n",
    "    f.write(text)\n",
    "    txt_no+=1\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
